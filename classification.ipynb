{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1- Tiền xử lý dữ liệu: Làm sạch dữ liệu, loại bỏ dư thừa, tách từ, stopword\n\n2- Chia bộ dữ liệu thành Train/Test với tỉ lệ 0.7\n\n3- Sử dụng WordEmbedding của thư viện Keras hỗ trợ cho dữ liệu đã xử lý ở trên, lưu kết quả wordembedding đó ra 1 file KerasWordEmbedding.txt\n\n4- Sử dụng pretrained word embedding Fasttext (Facebook AI Research), lấy wordembedding của bộ dữ liệu trên ra 1 file FastTextWordEmbedding.txt\n\n5- Sử dụng PhoBert cho bộ dữ liệu trên, lưu kết quả ra file PhoBertEmbedding.txt\n\n6- Sử dụng 1 trong 3 kết quả ở các câu 2,3,4 là đầu vào cho các mô hình học sâu: MLP, RNN, LSTM, BiLSTM và CNN (các tham số của mô hình tự xây dựng) cho bài toán phân lớp ý kiến người dùng. In ra các tham số của mô hình huấn luyện\n\n7- Đánh giá với 3 độ đo Accuracy, Confusion Matrix và F1-score và lưu kết quả ra 1 file\n\n8- Với mô hình học sâu có kết quả cao nhất ở trên, sử dụng điểm Checkpoint để lưu kết quả huấn luyện với epoch cho kết quả cao nhất\n\n9- Người dùng nhập vào một câu, sử dụng mô hình đã lưu ở trên dự đoán ý kiến của người dùng và in ra kết quả","metadata":{"id":"221a4c4a"}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyvi\n!pip install keras-self-attention","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BATCH_SIZE = 100\nSEED = 61\n\nimport re\nimport time\nimport string\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\n# tf.keras.utils.set_random_seed(SEED)\n\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Embedding,SimpleRNN, LSTM, Input, Flatten, Convolution1D, MaxPool1D, Bidirectional\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import layers, Sequential\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow import keras\n\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n\nfrom gensim.models.fasttext import FastText\nfrom gensim.models import Word2Vec\n\nimport fasttext\nimport fasttext.util\n\nimport matplotlib.pyplot as plt\n\nfrom pyvi import ViTokenizer\n\nfrom tqdm import tqdm, notebook\nfrom keras_self_attention import SeqSelfAttention\n\n\n# import torch\n# from transformers import AutoModel, AutoTokenizer","metadata":{"id":"d9dd81f0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# colab_path = '/content/drive/MyDrive/DACNTT2/tasks/Text Sentiment Analysis/'\n\ntrain_path = '../input/cleaned-sentiment-text/train.csv'\nvalidation_path = '../input/cleaned-sentiment-text/validation.csv'\ntest_path = '../input/cleaned-sentiment-text/test.csv'","metadata":{"id":"9774e0d0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_path = '../input/text-sentiment-data/train.csv'\n# validation_path = '../input/text-sentiment-data/validation.csv'\n# test_path = '../input/text-sentiment-data/test.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data is already cleaned and splitted in 3 parts: train, validation and test\ntrain_df = pd.read_csv(train_path, index_col=0)\nvalidation_df = pd.read_csv(validation_path, index_col=0)\ntest_df = pd.read_csv(test_path, index_col=0)\nNUM_CLASSES = len(train_df['label'].unique())\nindex2class = {0:'neg', 1:'pos'}\nclass2index = {'neg': 0, 'pos':1}\n\nprint('Number of train data:', train_df.shape[0])\nprint('Number of validation data:', validation_df.shape[0])\nprint('Number of test data:', test_df.shape[0])\nprint('Number of classes:', NUM_CLASSES, '->', train_df['label'].unique())\n\ntrain_df.head()","metadata":{"id":"7806838d","outputId":"7e266a01-c9d2-47e5-e638-4cdb59778201","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X\ntrain_data = train_df.iloc[:, 0].to_numpy()\nvalidation_data = validation_df.iloc[:, 0].to_numpy()\ntest_data = test_df.iloc[:, 0].to_numpy()\nwhole_data = np.concatenate((train_data, validation_data, test_data), dtype=object)","metadata":{"id":"4ca4ac4d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y\nlabel_train = np.array([class2index[i] for i in train_df.iloc[:, 1]])\nlabel_validation = np.array([class2index[i] for i in validation_df.iloc[:, 1]])\nlabel_test = np.array([class2index[i] for i in test_df.iloc[:, 1]])\nlabel_whole = np.concatenate((label_train, label_validation, label_test))","metadata":{"id":"8844ac55","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAXLEN = max([len(x.split()) for x in whole_data]) # = 492\nEMBEDDING_DIM = 100","metadata":{"id":"c0729bcc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6 - Sử dụng 1 trong 3 kết quả ở các câu 2,3,4 là đầu vào cho các mô hình học sâu: MLP, RNN, LSTM, BiLSTM và CNN (các tham số của mô hình tự xây dựng) cho bài toán phân lớp ý kiến người dùng. In ra các tham số của mô hình huấn luyện","metadata":{"id":"9bbb713d"}},{"cell_type":"code","source":"# # load fasttext trained embedding layer weights to get feature vector accordingly\n# ft_loaded = fasttext.load_model('data/embedding/fasttext/FastTextEmbeddingModel.bin')","metadata":{"id":"bc95d66a","outputId":"ae3b9076-83ad-4796-df38-3d4dc2af36e7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def fasttext_pretrained_embed_sentence(sent):\n#     embedded_sent = np.zeros((EMBEDDING_DIM, ))\n#     for i, word in enumerate(sent.split()):\n#         embedded_sent += ft_loaded.get_word_vector(word)\n#     return (embedded_sent/len(sent.split())).ravel().tolist()\n\n# fasttext_pretrained_embed = np.frompyfunc(fasttext_pretrained_embed_sentence, 1, 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train = np.array(fasttext_pretrained_embed(train_data).tolist())\n# X_validation = np.array(fasttext_pretrained_embed(validation_data).tolist())\n# X_test = np.array(fasttext_pretrained_embed(test_data).tolist())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.save('data/embedding/fasttext/X_train.npy', X_train)\n# np.save('data/embedding/fasttext/X_validation.npy', X_validation)\n# np.save('data/embedding/fasttext/X_test.npy', X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load saved embedded FastText features data\n# data/embedding/fasttext/X_train.npy\n# this is features from already cleaned text\nX_train = np.load('../input/embeddings/X_train.npy', allow_pickle=True)\nX_validation = np.load('../input/embeddings/X_validation.npy', allow_pickle=True)\nX_test = np.load('../input/embeddings/X_test.npy', allow_pickle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MLP","metadata":{"id":"a0863d16"}},{"cell_type":"code","source":"early_stopping = EarlyStopping(patience=5, monitor=\"val_loss\", verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=5, verbose=1)\n# mlp.optimizer.get_config()\n# adam initial learning rate = 0.001","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp = Sequential()\nmlp.add(Input(shape=(EMBEDDING_DIM,)))\nmlp.add(Dense(200, activation='relu'))\nmlp.add(Dense(100, activation='relu'))\nmlp.add(Dense(20, activation='relu'))\nmlp.add(Dense(1, activation='sigmoid'))","metadata":{"id":"b9348769","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mlp.summary())\ncheckpoint_mlp = ModelCheckpoint('./model_checkpoint/mlp.h5', save_best_only=True, verbose=1)\nmlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(mlp, rankdir='LR', show_shapes=True)","metadata":{"id":"0467f83b","outputId":"0f883303-b9ce-405c-f429-5cac9285ab16","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mlp.fit(X_train, label_train, epochs=2, batch_size=100,\n#         validation_data=(X_validation, label_validation), \n#         callbacks=[checkpoint_mlp, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RNN","metadata":{}},{"cell_type":"code","source":"rnn = Sequential()\nrnn.add(Input(shape=(1, EMBEDDING_DIM)))\nrnn.add(SimpleRNN(128, return_sequences=True))\nrnn.add(SimpleRNN(128, return_sequences=False))\nrnn.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rnn.summary())\ncheckpoint_rnn = ModelCheckpoint('./model_checkpoint/rnn.h5', save_best_only=True, verbose=1)\nrnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(rnn, rankdir='LR', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# rnn.fit(X_train.reshape(X_train.shape[0], -1, 100), label_train, epochs=100, batch_size=100,\n#         validation_data=(X_validation.reshape(X_validation.shape[0], -1, 100), label_validation), \n#         callbacks=[checkpoint_rnn, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"code","source":"lstm = Sequential()\nlstm.add(Input(shape=(1, EMBEDDING_DIM)))\nlstm.add(LSTM(256, return_sequences=True))\nlstm.add(LSTM(128, return_sequences=True))\nlstm.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lstm.summary())\ncheckpoint_lstm = ModelCheckpoint('./model_checkpoint/lstm.h5', save_best_only=True, verbose=1)\nlstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(lstm, rankdir='LR', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm.fit(X_train.reshape(X_train.shape[0], -1, 100), label_train, epochs=2, batch_size=100,\n        validation_data=(X_validation.reshape(X_validation.shape[0], -1, 100), label_validation), \n        callbacks=[checkpoint_lstm, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM with Self-Attention","metadata":{}},{"cell_type":"code","source":"lstm1_input = Input(shape=(1, EMBEDDING_DIM))\nself_attention = SeqSelfAttention() (lstm1_input)\nx = LSTM(256, return_sequences=True) (self_attention)\nx = LSTM(128, return_sequences=True) (x)\nlstm1_output = Dense(1, activation='sigmoid') (x)\nlstm1 = Model(lstm1_input, lstm1_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(lstm1.summary())\ncheckpoint_lstm1 = ModelCheckpoint('./model_checkpoint/lstm1.h5', save_best_only=True, verbose=1)\nlstm1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(lstm1, rankdir='LR', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm1.fit(X_train.reshape(X_train.shape[0], -1, 100), label_train, epochs=2, batch_size=100,\n        validation_data=(X_validation.reshape(X_validation.shape[0], -1, 100), label_validation), \n        callbacks=[checkpoint_lstm1, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Retrieve the config\n# config = lstm1.get_config()\n\n# # At loading time, register the custom objects with a `custom_object_scope`:\n# custom_objects = {'seq_self_attention_1': self_attention}\n# with keras.utils.custom_object_scope(custom_objects):\n#     new_model = keras.Model.from_config(config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bidirectional LSTM","metadata":{}},{"cell_type":"code","source":"bi_lstm = Sequential()\nbi_lstm.add(Bidirectional(LSTM(10, return_sequences=True), input_shape=(1, EMBEDDING_DIM)))\nbi_lstm.add(Bidirectional(LSTM(10)))\nbi_lstm.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(bi_lstm.summary())\ncheckpoint_bi_lstm = ModelCheckpoint('./model_checkpoint/bi_lstm.h5', save_best_only=True, verbose=1)\nbi_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(bi_lstm, rankdir='LR', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bi_lstm.fit(X_train.reshape(X_train.shape[0], -1, 100), label_train, epochs=100, batch_size=100,\n#         validation_data=(X_validation.reshape(X_validation.shape[0], -1, 100), label_validation), \n#         callbacks=[checkpoint_bi_lstm, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"code","source":"'''Initializing the Convolutional Neural Network'''\ncnn = Sequential()\ncnn.add(Convolution1D(64, kernel_size=5, input_shape=(EMBEDDING_DIM, 1), activation='relu'))\ncnn.add(MaxPool1D(pool_size=2))\ncnn.add(Convolution1D(32, kernel_size=5, activation='relu'))\ncnn.add(MaxPool1D(pool_size=2))\ncnn.add(Flatten())\ncnn.add(Dense(32, activation='relu'))\ncnn.add(Dense(1, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cnn.summary())\ncheckpoint_cnn = ModelCheckpoint('./model_checkpoint/cnn.h5', save_best_only=True, verbose=1)\ncnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nplot_model(cnn, rankdir='LR', show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cnn.fit(X_train.reshape(X_train.shape[0], 100, -1), label_train, epochs=100, batch_size=100,\n#         validation_data=(X_validation.reshape(X_validation.shape[0], 100, -1), label_validation), \n#         callbacks=[checkpoint_cnn, reduce_lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7 - Đánh giá với 3 độ đo Accuracy, Confusion Matrix và F1-score và lưu kết quả ra 1 file","metadata":{}},{"cell_type":"markdown","source":"# 8 - Với mô hình học sâu có kết quả cao nhất ở trên, sử dụng điểm Checkpoint để lưu kết quả huấn luyện với epoch cho kết quả cao nhất","metadata":{}},{"cell_type":"code","source":"# # load model with best saved checkpoint\n# mlp = load_model('./model_checkpoint/mlp.h5')\n# rnn = load_model('./model_checkpoint/rnn.h5')\n# lstm = load_model('./model_checkpoint/lstm.h5')\nlstm1 = load_model('./model_checkpoint/lstm1.h5', custom_objects={'SeqSelfAttention': SeqSelfAttention})\n# bi_lstm = load_model('./model_checkpoint/bi_lstm.h5')\n# cnn = load_model('./model_checkpoint/cnn.h5')","metadata":{"id":"82pOAjEXjAYa","outputId":"96424c37-468e-4fa3-9dde-34547218ddfa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_pred(pred):\n    out = []\n    for p in pred.flatten():\n        if p >= 0.5:\n            out.append(1)\n        else:\n            out.append(0)\n    return out ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, X_test):\n    pred = convert_pred(model.predict(X_test))\n    print('Accuracy:', accuracy_score(label_test, pred))\n    print('F1-scrore:', f1_score(label_test, pred))\n    cm = confusion_matrix(label_test, pred, labels=list(index2class.keys()))\n    cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                  display_labels=list(index2class.keys()))\n    cm_disp.plot()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print('MLP')\n# evaluate(mlp, X_test)\n# print('RNN')\n# evaluate(rnn, X_test.reshape(X_test.shape[0], -1, 100))\nprint('LSTM')\nevaluate(lstm, X_test.reshape(X_test.shape[0], -1, 100))\nprint('LSTM with Attention')\nevaluate(lstm1, X_test.reshape(X_test.shape[0], -1, 100))\n# print('Bi-LSTM')\n# evaluate(bi_lstm, X_test.reshape(X_test.shape[0], -1, 100))\n# print('CNN')\n# evaluate(cnn, X_test.reshape(X_test.shape[0], 100, -1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9 - Người dùng nhập vào một câu, sử dụng mô hình đã lưu ở trên dự đoán ý kiến của người dùng và in ra kết quả","metadata":{}},{"cell_type":"code","source":"# def predict_sentiment(sent):\n#     # missing preprocess\n#     embedded_sent = fasttext_pretrained_embed_sentence(sent)\n#     pred = convert_pred(mlp.predict(np.array([fasttext_pretrained_embed_sentence(sent)])).ravel())\n#     return index2class[pred[0]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(predict_sentiment('quán này dở'))\n# print(predict_sentiment('thức_ăn ngon'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}